{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.71428571428571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = pd.read_csv('HR Analytics.csv')\n",
    "hr_dummies=pd.get_dummies(hr)\n",
    "hr_dummies.head()\n",
    "train,test =train_test_split(hr_dummies,test_size=0.3,random_state=100)\n",
    "train_y =train['Attrition']\n",
    "test_y =test['Attrition']\n",
    "\n",
    "train_x=train.drop('Attrition',axis=1)\n",
    "test_x=test.drop('Attrition',axis=1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model =RandomForestClassifier(random_state=100)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "test_pred =model.predict(test_x)\n",
    "df_pred =pd.DataFrame({'actual':test_y,'predicted':test_pred})\n",
    "df_pred['pred_status']=df_pred['actual'] == df_pred['predicted']\n",
    "df_pred[df_pred['pred_status']==True].shape[0]/df_pred.shape[0] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#confusion matrix\n",
    "- True positive\n",
    "- True Negative\n",
    "- False Positive\n",
    "- False Negative\n",
    "- confusion matrix\n",
    "\n",
    "- Predicted Actual\n",
    "- 0,          0 -  TN\n",
    "- 0,          1 -  FN\n",
    "- 1,          0 -  FP\n",
    "- 1,          1 -  TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>pred_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predicted  pred_status\n",
       "880        0          0         True\n",
       "152        0          0         True\n",
       "1466       0          0         True\n",
       "1084       0          0         True\n",
       "1086       0          0         True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['status']=np.where((df_pred['actual']==0) & (df_pred['predicted']==1) ,'FP',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred[df_pred['status']=='FP'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred=df_pred.drop('status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[367,   4],\n",
       "       [ 59,  11]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(df_pred['actual'],df_pred['predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367 4 59 11\n"
     ]
    }
   ],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(df_pred['actual'],df_pred['predicted']).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy in confusion matrix = tf+tn/tf+tn+fp+fn\n",
    "- sensitivity = tp/tp+fn = % of positive correct prediction\n",
    "- my ability to predict 1's as 1 is called sensitivity\n",
    "- my ability to predict 0's as 0 is called specificity\n",
    "- specificity = tn /fp+tn = % of negative correct prediction\n",
    "- inbalanced class will have specificity more but sensitivity more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.00453514739229"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =DecisionTreeClassifier(random_state=100)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "test_pred =model.predict(test_x)\n",
    "df_pred =pd.DataFrame({'actual':test_y,'predicted':test_pred})\n",
    "df_pred['pred_status']=df_pred['actual'] == df_pred['predicted']\n",
    "df_pred[df_pred['pred_status']==True].shape[0]/df_pred.shape[0] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive:32\n",
      "true negative:312\n",
      "false positive:59\n",
      "false negative:38\n"
     ]
    }
   ],
   "source": [
    "tp =df_pred[(df_pred['predicted']==1) &(df_pred['actual']==1)].shape[0]\n",
    "tn =df_pred[(df_pred['predicted']==0) &(df_pred['actual']==0)].shape[0]\n",
    "fp =df_pred[(df_pred['predicted']==1) &(df_pred['actual']==0)].shape[0]\n",
    "fn=df_pred[(df_pred['predicted']==0) &(df_pred['actual']==1)].shape[0]\n",
    "print(\"true positive:%d\" %tp)\n",
    "print(\"true negative:%d\" %tn)\n",
    "print(\"false positive:%d\" %fp)\n",
    "print(\"false negative:%d\" %fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312 59 38 32\n"
     ]
    }
   ],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(df_pred['actual'],df_pred['predicted']).ravel()\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.780045351473923"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accuracy\n",
    "(312+32)/(441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45714285714285713"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sensitivity =tp/tp+fn\n",
    "32/(32+38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8409703504043127"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specificity =tn/tn+fp\n",
    "312/(312+59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3516483516483517"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32/(32+59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.84      0.87       371\n",
      "          1       0.35      0.46      0.40        70\n",
      "\n",
      "avg / total       0.81      0.78      0.79       441\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(df_pred['actual'],df_pred['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 19, 43, 27)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(random_state=100)\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "test_pred =model.predict(test_x)\n",
    "tn,fp,fn,tp = confusion_matrix(test_y,test_pred).ravel()\n",
    "tn,fp,fn,tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "ab_accuracy=(352+27)/(352+43+19+27) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.57142857142858"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sensitivity\n",
    "ab_sensitivity=tp/(tp+fn) * 100\n",
    "ab_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.87870619946092"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specificity\n",
    "ab_specificity =tn /(tn+fp) *100\n",
    "ab_specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.Series(np.random.randint(1,100,100)).value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    80\n",
       "2    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_samples=[]\n",
    "for i in range(100):\n",
    "    random_samples.append(np.random.choice([1,2,3],p=[0,0.2,0.8]))\n",
    "pd.Series(random_samples).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification  Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dt1 =train.iloc[np.random.randint(1,train.shape[0],train.shape[0])]\n",
    "all_cols =np.array(train.drop('Attrition',axis=1).columns)\n",
    "cols_position = np.random.randint(1,len(all_cols),3)\n",
    "random_cols = all_cols[cols_position]\n",
    "samples_dt1.shape\n",
    "samples_dt1_x =samples_dt1.drop('Attrition',axis=1)[random_cols]\n",
    "samples_dt1_y =samples_dt1['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158    5\n",
       "835     5\n",
       "1437    4\n",
       "983     4\n",
       "337     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(samples_dt1.index).value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1 =DecisionTreeClassifier(max_depth=1)\n",
    "dt1.fit(samples_dt1_x,samples_dt1_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred= dt1.predict(test_x[random_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predicted\n",
       "880        0          0\n",
       "152        0          0\n",
       "1466       0          0\n",
       "1084       0          0\n",
       "1086       0          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred =pd.DataFrame({'actual':test_y,'predicted':test_pred})\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(371, 0, 70, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn,fp,fn,tp = confusion_matrix(test_y,test_pred).ravel()\n",
    "tn,fp,fn,tp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - positive -1 negative -1\n",
    " - DT1- random rows and random cols\n",
    "  - depth=1 ,with equal probablities\n",
    " - predict for train data\n",
    " - Et = no of wrong predictions/total no of predictions\n",
    " - dt = 1/2 log(1-et/et)\n",
    " - calculate probablity for each sample on train data\n",
    " - new probablity for each sample = old probability * exp(-alphat *  actual value * predicted value) / z\n",
    " - D2 - sample rows with unequal probabilities,random columns - decision stump\n",
    " - repeat the process for new trees\n",
    " - Error rate = fp+fn /(tp+tn+fp+fn)\n",
    " - Et=1- bad classifier  : alphat - negative\n",
    " - Et=0.5-average classifier: aplhat - zero \n",
    " - Et=0- good classifier:alphat-positive\n",
    "  dt+1= (dt(1)) * exponential(alphat * yt(i) * ht(i)/z \n",
    "  probablitiy of sample   y           predicted     new probability (exp(-alphat * actual value * predicted))\n",
    "     1/1029             1(positive)  1(positive)          0.00079/z      E(-alphat)  \n",
    "     1/1029             1(positive)  0(negative)          0.0011/z       E(alphat)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Differences between Random Forest and Adaptive Boosting\n",
    "  - Random Forest\n",
    "    - Trees are independent on each other\n",
    "    - can run on parallel\n",
    "    - row samples with equal probability\n",
    "    - full tree can be created\n",
    "  - Adaptive Boosting\n",
    "    - Trees are dependent on each other\n",
    "    - sequential training\n",
    "    - rows are sampled with unequal probability\n",
    "    - decision trees are created(depth=1)\n",
    "    - Each decision tree is a weak learner\n",
    "    - combine weak learners to generate strong learner\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.151927437641723"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Et =fp+fn/(tp+tn+fp+fn)\n",
    "Et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365924906076799"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "alphat = 1/2 * (math.log((1-0.158)/0.158))\n",
    "alphat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
